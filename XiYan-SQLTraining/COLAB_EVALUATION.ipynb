{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XiYan-SQL Evaluation on Google Colab\n",
    "\n",
    "This notebook provides a complete evaluation pipeline for XiYan-SQL models on Google Colab.\n",
    "\n",
    "## What this notebook does:\n",
    "1. ‚úÖ Installs dependencies\n",
    "2. ‚úÖ Clones the repository\n",
    "3. ‚úÖ Mounts Google Drive\n",
    "4. ‚úÖ Copies model from Google Drive\n",
    "5. ‚úÖ Runs inference on test dataset\n",
    "6. ‚úÖ Runs evaluation (execution accuracy)\n",
    "\n",
    "## Prerequisites:\n",
    "- Upload your trained model to Google Drive\n",
    "- Enable GPU runtime in Colab (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "- Test dataset is already in the repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "Install all required packages for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq libaio-dev  # Required for DeepSpeed\n",
    "\n",
    "print(\"üì¶ Installing Python packages...\")\n",
    "print(\"‚ö†Ô∏è  Note: Installing in specific order to avoid numpy/DeepSpeed conflicts.\\n\")\n",
    "\n",
    "# Install DeepSpeed AFTER numpy and torch are set\n",
    "print(\"\\nüîß Installing DeepSpeed (may show some warnings)...\")\n",
    "!pip install -q --disable-pip-version-check --no-cache-dir deepspeed\n",
    "\n",
    "# Install remaining packages\n",
    "!pip install -q --disable-pip-version-check llama-index>=0.9.6.post2\n",
    "!pip install -q --disable-pip-version-check modelscope>=1.33.0\n",
    "!pip install -q --disable-pip-version-check mysql-connector-python>=9.5.0\n",
    "!pip install -q --disable-pip-version-check \"protobuf>=6.33.3\"\n",
    "!pip install -q --disable-pip-version-check psycopg2-binary>=2.9.11\n",
    "!pip install -q --disable-pip-version-check swanlab>=0.7.6\n",
    "!pip install -q --disable-pip-version-check textdistance>=4.6.3\n",
    "!pip install -q --disable-pip-version-check jedi>=0.16\n",
    "\n",
    "# Install flash-attn (optional, for faster attention)\n",
    "print(\"\\nüî® Attempting to install flash-attn (this may take a few minutes)...\")\n",
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    [\"pip\", \"install\", \"-q\", \"--no-build-isolation\", \"flash-attn\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ flash-attn installed successfully\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  flash-attn installation failed (this is optional, continuing without it)\")\n",
    "\n",
    "print(\"\\n‚úÖ Core dependencies installed!\")\n",
    "print(\"\\nüí° If you see numpy warnings, they are expected and won't affect training.\")\n",
    "\n",
    "# Verify installation\n",
    "print(\"\\nüîç Verifying installation...\")\n",
    "try:\n",
    "    import torch\n",
    "    import transformers\n",
    "    import accelerate\n",
    "    import deepspeed\n",
    "    import peft\n",
    "    import numpy as np\n",
    "\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    print(f\"‚úÖ Transformers: {transformers.__version__}\")\n",
    "    print(f\"‚úÖ Accelerate: {accelerate.__version__}\")\n",
    "    print(f\"‚úÖ DeepSpeed: {deepspeed.__version__}\")\n",
    "    print(f\"‚úÖ PEFT: {peft.__version__}\")\n",
    "    print(f\"‚úÖ NumPy: {np.__version__}\")\n",
    "    print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"‚úÖ GPU Memory: {gpu_mem:.1f} GB\")\n",
    "\n",
    "        if gpu_mem >= 14:\n",
    "            print(\"\\nüéØ Your GPU has 15GB+ memory - perfect for optimized training!\")\n",
    "        elif gpu_mem >= 10:\n",
    "            print(\"\\nüìä Your GPU has 12GB memory - good for moderate training.\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  Your GPU has limited memory - training will use conservative settings.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå No GPU detected! Make sure to enable GPU in Runtime ‚Üí Change runtime type\")\n",
    "\n",
    "    print(\"\\nüöÄ Ready to proceed!\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"\\n‚ùå Import error: {e}\")\n",
    "    print(\"\\nüîÑ If you see numpy errors, restart runtime and run this cell again.\")\n",
    "    print(\"   Go to: Runtime ‚Üí Restart runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository\n",
    "\n",
    "Clone the XiYan-SQL repository to Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to content directory\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/content')\n",
    "\n",
    "# Clone the repository\n",
    "# ‚ö†Ô∏è UPDATE THIS with your repository URL\n",
    "REPO_URL = \"https://github.com/rezaarrazi/XiYan-SQL.git\"\n",
    "\n",
    "if not os.path.exists('XiYan-SQL'):\n",
    "    os.system(f'git clone {REPO_URL}')\n",
    "    print(\"‚úÖ Repository cloned successfully\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "\n",
    "# Navigate to evaluation directory\n",
    "os.chdir('XiYan-SQL/XiYan-SQLTraining/evaluation')\n",
    "\n",
    "# Add to Python path\n",
    "TRAINING_DIR = os.path.dirname(os.getcwd())\n",
    "if TRAINING_DIR not in sys.path:\n",
    "    sys.path.insert(0, TRAINING_DIR)\n",
    "if os.path.dirname(TRAINING_DIR) not in sys.path:\n",
    "    sys.path.insert(0, os.path.dirname(TRAINING_DIR))\n",
    "\n",
    "print(f\"\\nüìÅ Current directory: {os.getcwd()}\")\n",
    "print(f\"‚úÖ Python path configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Mount Google Drive\n",
    "\n",
    "Mount your Google Drive to access the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted successfully\")\n",
    "print(\"\\nüìÇ Drive path: /content/drive/MyDrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Copy Model from Google Drive\n",
    "\n",
    "Copy your trained model from Google Drive. The model can be either:\n",
    "- A merged model (single folder)\n",
    "- A base model + LoRA adapter (two separate folders)\n",
    "\n",
    "**Configure the path below to match your Google Drive structure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è CONFIGURE THIS: Path to your model in Google Drive\n",
    "# Option 1: Merged model (single folder)\n",
    "MODEL_DRIVE_PATH = \"/content/drive/MyDrive/XiYan-SQL/Trained-Models/your-model-name\"\n",
    "\n",
    "# Option 2: Base model + LoRA adapter (if using separate adapter)\n",
    "BASE_MODEL_DRIVE_PATH = \"/content/drive/MyDrive/XiYan-SQL/Models/Qwen/Qwen2.5-Coder-3B-Instruct\"\n",
    "LORA_ADAPTER_DRIVE_PATH = \"/content/drive/MyDrive/XiYan-SQL/Trained-Models/your-adapter-name\"\n",
    "\n",
    "# Choose which model to use:\n",
    "# - \"merged\": Use merged model (single path)\n",
    "# - \"adapter\": Use base model + LoRA adapter (two paths)\n",
    "MODEL_TYPE = \"merged\"  # Change to \"adapter\" if using separate adapter\n",
    "\n",
    "# Target directory in the repository\n",
    "MODEL_TARGET_DIR = \"../train/model/Qwen\"\n",
    "os.makedirs(MODEL_TARGET_DIR, exist_ok=True)\n",
    "\n",
    "if MODEL_TYPE == \"merged\":\n",
    "    # Copy merged model\n",
    "    if os.path.exists(MODEL_DRIVE_PATH):\n",
    "        model_name = os.path.basename(MODEL_DRIVE_PATH)\n",
    "        target_path = os.path.join(MODEL_TARGET_DIR, model_name)\n",
    "        \n",
    "        if os.path.exists(target_path):\n",
    "            print(f\"‚ö†Ô∏è  Model already exists at {target_path}\")\n",
    "            print(\"Skipping copy (delete manually if you want to re-copy)\")\n",
    "        else:\n",
    "            print(f\"üì• Copying merged model from {MODEL_DRIVE_PATH}...\")\n",
    "            shutil.copytree(MODEL_DRIVE_PATH, target_path)\n",
    "            print(f\"‚úÖ Model copied to {target_path}\")\n",
    "        \n",
    "        MODEL_PATH = target_path\n",
    "        LORA_PATH = \"\"  # No adapter needed for merged model\n",
    "    else:\n",
    "        print(f\"‚ùå Model not found at {MODEL_DRIVE_PATH}\")\n",
    "        print(\"\\nPlease check:\")\n",
    "        print(\"1. Google Drive is mounted correctly\")\n",
    "        print(\"2. The model path is correct\")\n",
    "        MODEL_PATH = None\n",
    "        LORA_PATH = \"\"\n",
    "        \n",
    "elif MODEL_TYPE == \"adapter\":\n",
    "    # Copy base model\n",
    "    if os.path.exists(BASE_MODEL_DRIVE_PATH):\n",
    "        base_model_name = os.path.basename(BASE_MODEL_DRIVE_PATH)\n",
    "        base_target_path = os.path.join(MODEL_TARGET_DIR, base_model_name)\n",
    "        \n",
    "        if os.path.exists(base_target_path):\n",
    "            print(f\"‚ö†Ô∏è  Base model already exists at {base_target_path}\")\n",
    "        else:\n",
    "            print(f\"üì• Copying base model from {BASE_MODEL_DRIVE_PATH}...\")\n",
    "            shutil.copytree(BASE_MODEL_DRIVE_PATH, base_target_path)\n",
    "            print(f\"‚úÖ Base model copied to {base_target_path}\")\n",
    "        \n",
    "        MODEL_PATH = base_target_path\n",
    "    else:\n",
    "        print(f\"‚ùå Base model not found at {BASE_MODEL_DRIVE_PATH}\")\n",
    "        MODEL_PATH = None\n",
    "    \n",
    "    # Copy LoRA adapter\n",
    "    if os.path.exists(LORA_ADAPTER_DRIVE_PATH):\n",
    "        adapter_name = os.path.basename(LORA_ADAPTER_DRIVE_PATH)\n",
    "        adapter_target_path = os.path.join(\"../train/output\", adapter_name)\n",
    "        os.makedirs(os.path.dirname(adapter_target_path), exist_ok=True)\n",
    "        \n",
    "        if os.path.exists(adapter_target_path):\n",
    "            print(f\"‚ö†Ô∏è  Adapter already exists at {adapter_target_path}\")\n",
    "        else:\n",
    "            print(f\"üì• Copying LoRA adapter from {LORA_ADAPTER_DRIVE_PATH}...\")\n",
    "            shutil.copytree(LORA_ADAPTER_DRIVE_PATH, adapter_target_path)\n",
    "            print(f\"‚úÖ Adapter copied to {adapter_target_path}\")\n",
    "        \n",
    "        LORA_PATH = adapter_target_path\n",
    "    else:\n",
    "        print(f\"‚ùå Adapter not found at {LORA_ADAPTER_DRIVE_PATH}\")\n",
    "        LORA_PATH = \"\"\n",
    "\n",
    "if MODEL_PATH:\n",
    "    print(f\"\\nüìå Model path: {MODEL_PATH}\")\n",
    "    if LORA_PATH:\n",
    "        print(f\"üìå LoRA adapter path: {LORA_PATH}\")\n",
    "    print(\"\\n‚úÖ Model ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure Evaluation Parameters\n",
    "\n",
    "Set up the evaluation configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Check GPU memory for optimal batch size\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total', '--format=csv,noheader,nounits'], \n",
    "                          capture_output=True, text=True)\n",
    "    gpu_memory_mb = int(result.stdout.strip())\n",
    "    gpu_memory_gb = gpu_memory_mb / 1024\n",
    "    print(f\"üéÆ Detected GPU Memory: {gpu_memory_gb:.1f} GB\")\n",
    "    \n",
    "    # Detect GPU architecture for flash attention\n",
    "    gpu_name_result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], \n",
    "                                     capture_output=True, text=True)\n",
    "    gpu_name = gpu_name_result.stdout.strip()\n",
    "    print(f\"üéÆ GPU: {gpu_name}\")\n",
    "    \n",
    "    supports_flash = any(x in gpu_name.upper() for x in ['A100', 'A10', 'RTX 30', 'RTX 40', 'H100', 'L4'])\n",
    "    if supports_flash:\n",
    "        print(f\"‚úÖ Flash Attention supported!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Flash Attention not supported on this GPU\")\n",
    "except:\n",
    "    gpu_memory_gb = 15.0\n",
    "    supports_flash = False\n",
    "    print(f\"‚ö†Ô∏è  Could not detect GPU, assuming {gpu_memory_gb} GB\")\n",
    "\n",
    "# Auto-configure batch size based on GPU memory\n",
    "if gpu_memory_gb >= 40:\n",
    "    BATCH_SIZE = 4\n",
    "elif gpu_memory_gb >= 24:\n",
    "    BATCH_SIZE = 2\n",
    "elif gpu_memory_gb >= 15:\n",
    "    BATCH_SIZE = 1\n",
    "else:\n",
    "    BATCH_SIZE = 1\n",
    "\n",
    "# Check for db_conn.json (repository or Google Drive)\n",
    "DB_CONN_REPO_PATH = \"../data/data_warehouse/train/db_conn.json\"\n",
    "DB_CONN_DRIVE_PATH = \"/content/drive/MyDrive/XiYan-SQL/db_conn.json\"\n",
    "if os.path.exists(DB_CONN_REPO_PATH):\n",
    "    DB_CONN_CONFIG = DB_CONN_REPO_PATH\n",
    "elif os.path.exists(DB_CONN_DRIVE_PATH):\n",
    "    DB_CONN_CONFIG = DB_CONN_DRIVE_PATH\n",
    "else:\n",
    "    DB_CONN_CONFIG = \"\"\n",
    "\n",
    "# Evaluation configuration\n",
    "EVAL_CONFIG = {\n",
    "    # Model paths (set in Step 4)\n",
    "    \"model_path\": MODEL_PATH if 'MODEL_PATH' in globals() else \"../train/model/Qwen/Qwen2.5-Coder-3B-Instruct\",\n",
    "    \"lora_path\": LORA_PATH if 'LORA_PATH' in globals() else \"\",\n",
    "    \n",
    "    # Test dataset (already in repository)\n",
    "    \"test_set_path\": \"datasets/nl2sql_standard_test.json\",\n",
    "    \n",
    "    # Experiment version (for output naming)\n",
    "    \"expr_version\": \"colab_eval\",\n",
    "    \n",
    "    # Inference parameters\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"use_flash_attention\": supports_flash,\n",
    "    \"max_samples\": None,  # Set to a number (e.g., 100) to test on subset\n",
    "    \n",
    "    # Evaluation parameters (for sql_eval.py)\n",
    "    \"db_conn_config\": DB_CONN_CONFIG if \"DB_CONN_CONFIG\" in globals() else \"\",  # Set if found in repo or Drive\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Evaluation Configuration:\")\n",
    "print(f\"  Model: {EVAL_CONFIG['model_path']}\")\n",
    "if EVAL_CONFIG[\"lora_path\"]:\n",
    "    print(f\"  LoRA Adapter: {EVAL_CONFIG['lora_path']}\")\n",
    "print(f\"  Test Dataset: {EVAL_CONFIG['test_set_path']}\")\n",
    "print(f\"  Batch Size: {EVAL_CONFIG['batch_size']}\")\n",
    "print(f\"  Flash Attention: {'‚úÖ Enabled' if EVAL_CONFIG['use_flash_attention'] else '‚ùå Disabled'}\")\n",
    "if EVAL_CONFIG[\"max_samples\"]:\n",
    "    print(f\"  Max Samples: {EVAL_CONFIG['max_samples']} (testing on subset)\")\n",
    "else:\n",
    "    print(f\"  Max Samples: All (full evaluation)\")\n",
    "if EVAL_CONFIG[\"db_conn_config\"]:\n",
    "    print(f\"  Database Config: {EVAL_CONFIG['db_conn_config']} ‚úÖ\")\n",
    "else:\n",
    "    print(f\"  Database Config: Not found (evaluation will be skipped)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Inference\n",
    "\n",
    "Generate SQL predictions for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Ensure we're in the evaluation directory\n",
    "os.chdir('/content/XiYan-SQL/XiYan-SQLTraining/evaluation')\n",
    "\n",
    "# Build inference command\n",
    "cmd = [\n",
    "    sys.executable, \"sql_infer.py\",\n",
    "    \"--model_name_or_path\", EVAL_CONFIG[\"model_path\"],\n",
    "    \"--test_set_path\", EVAL_CONFIG[\"test_set_path\"],\n",
    "    \"--expr_version\", EVAL_CONFIG[\"expr_version\"],\n",
    "    \"--batch_size\", str(EVAL_CONFIG[\"batch_size\"]),\n",
    "]\n",
    "\n",
    "# Add LoRA path if using adapter\n",
    "if EVAL_CONFIG[\"lora_path\"]:\n",
    "    cmd.extend([\"--lora_path\", EVAL_CONFIG[\"lora_path\"]])\n",
    "\n",
    "# Add flash attention flag if enabled\n",
    "if EVAL_CONFIG[\"use_flash_attention\"]:\n",
    "    cmd.append(\"--use_flash_attention\")\n",
    "\n",
    "# Add max samples if specified\n",
    "if EVAL_CONFIG[\"max_samples\"]:\n",
    "    cmd.extend([\"--max_samples\", str(EVAL_CONFIG[\"max_samples\"])])\n",
    "\n",
    "print(\"üöÄ Starting Inference\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìÅ Model: {EVAL_CONFIG['model_path']}\")\n",
    "print(f\"üìä Test Dataset: {EVAL_CONFIG['test_set_path']}\")\n",
    "print(f\"üíæ Output Version: {EVAL_CONFIG['expr_version']}\")\n",
    "print(f\"üì¶ Batch Size: {EVAL_CONFIG['batch_size']}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚è≥ Inference will take some time depending on dataset size...\")\n",
    "print(\"üí° Keep this tab active to prevent disconnection\\n\")\n",
    "\n",
    "# Show command\n",
    "print(\"üìù Running command:\")\n",
    "print(\" \".join(cmd))\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Run inference\n",
    "try:\n",
    "    result = subprocess.run(cmd, cwd=os.getcwd(), check=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ Inference completed successfully!\")\n",
    "        \n",
    "        # Find output file\n",
    "        import datetime\n",
    "        today = datetime.date.today().strftime('%Y%m%d')\n",
    "        output_dir = os.path.join(\"datasets\", \"output\", EVAL_CONFIG[\"expr_version\"])\n",
    "        output_file = os.path.join(output_dir, f\"{EVAL_CONFIG['expr_version']}_{today}_results.json\")\n",
    "        \n",
    "        if os.path.exists(output_file):\n",
    "            import json\n",
    "            with open(output_file, 'r') as f:\n",
    "                results = json.load(f)\n",
    "            print(f\"üìÅ Results saved to: {output_file}\")\n",
    "            print(f\"üìä Total predictions: {len(results)}\")\n",
    "            \n",
    "            # Store output path for evaluation\n",
    "            globals()['PRED_SQL_PATH'] = output_file\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Output file not found at expected path: {output_file}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"‚ùå Inference failed with return code {result.returncode}\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nüí° Common issues:\")\n",
    "        print(\"  - Model not found: Check MODEL_PATH in Step 4\")\n",
    "        print(\"  - Dataset not found: Check test_set_path\")\n",
    "        print(\"  - Out of memory: Try reducing batch_size\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during inference: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Configure db_conn.json\n",
    "\n",
    "The notebook will check for `db_conn.json` in the repository first (`data/data_warehouse/train/db_conn.json`), then Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for db_conn.json - first in repository, then Google Drive\n",
    "import os\n",
    "\n",
    "# Path in repository (relative to evaluation directory)\n",
    "DB_CONN_REPO_PATH = \"../data/data_warehouse/train/db_conn.json\"\n",
    "\n",
    "# Path in Google Drive (if you uploaded it there)\n",
    "DB_CONN_DRIVE_PATH = \"/content/drive/MyDrive/XiYan-SQL/db_conn.json\"\n",
    "\n",
    "# Check repository first\n",
    "if os.path.exists(DB_CONN_REPO_PATH):\n",
    "    print(f\"‚úÖ Database config found in repository\")\n",
    "    print(f\"üìÅ Location: {DB_CONN_REPO_PATH}\")\n",
    "    EVAL_CONFIG[\"db_conn_config\"] = DB_CONN_REPO_PATH\n",
    "elif os.path.exists(DB_CONN_DRIVE_PATH):\n",
    "    # Copy from Google Drive to current directory\n",
    "    import shutil\n",
    "    DB_CONN_TARGET_PATH = \"db_conn.json\"\n",
    "    shutil.copy2(DB_CONN_DRIVE_PATH, DB_CONN_TARGET_PATH)\n",
    "    print(f\"‚úÖ Database config copied from Google Drive\")\n",
    "    print(f\"üìÅ Location: {DB_CONN_TARGET_PATH}\")\n",
    "    EVAL_CONFIG[\"db_conn_config\"] = DB_CONN_TARGET_PATH\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Database config not found\")\n",
    "    print(f\"   Checked repository: {DB_CONN_REPO_PATH}\")\n",
    "    print(f\"   Checked Google Drive: {DB_CONN_DRIVE_PATH}\")\n",
    "    print(\"\\nüí° You can:\")\n",
    "    print(\"  1. Ensure db_conn.json exists at: data/data_warehouse/train/db_conn.json in the repository\")\n",
    "    print(\"  2. Or upload db_conn.json to Google Drive at the path above\")\n",
    "    print(\"  3. Or skip evaluation and manually inspect predictions\")\n",
    "    print(\"\\nüìù Example db_conn.json structure:\")\n",
    "    print(\"\"\"{\n",
    "  \"db_name\": \"your_database\",\n",
    "  \"db_user\": \"username\",\n",
    "  \"db_password\": \"password\",\n",
    "  \"db_host\": \"hostname\",\n",
    "  \"db_port\": 5432,\n",
    "  \"dialect\": \"postgresql\"  // or \"mysql\" or \"sqlite\"\n",
    "}\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "# Check if we have predictions and database config\n",
    "if 'PRED_SQL_PATH' not in globals() or not os.path.exists(globals().get('PRED_SQL_PATH', '')):\n",
    "    print(\"‚ùå No predictions found! Please run Step 6 (Inference) first.\")\n",
    "elif not EVAL_CONFIG.get('db_conn_config') or not os.path.exists(EVAL_CONFIG['db_conn_config']):\n",
    "    print(\"‚ö†Ô∏è  Database config not available. Skipping evaluation.\")\n",
    "    print(\"\\nüí° You can still inspect the predictions manually:\")\n",
    "    if 'PRED_SQL_PATH' in globals():\n",
    "        print(f\"   üìÅ Predictions file: {globals()['PRED_SQL_PATH']}\")\n",
    "else:\n",
    "    # Ensure we're in the evaluation directory\n",
    "    os.chdir('/content/XiYan-SQL/XiYan-SQLTraining/evaluation')\n",
    "    \n",
    "    # Build evaluation command\n",
    "    today = datetime.date.today().strftime('%Y%m%d')\n",
    "    save_eval_path = f\"datasets/output/{EVAL_CONFIG['expr_version']}/eval_results_{today}.json\"\n",
    "    os.makedirs(os.path.dirname(save_eval_path), exist_ok=True)\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable, \"sql_eval.py\",\n",
    "        \"--pred_sql_path\", globals()['PRED_SQL_PATH'],\n",
    "        \"--test_sql_path\", EVAL_CONFIG[\"test_set_path\"],\n",
    "        \"--db_conn_config\", EVAL_CONFIG[\"db_conn_config\"],\n",
    "        \"--save_eval_path\", save_eval_path,\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ Starting Evaluation\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìÅ Predictions: {globals()['PRED_SQL_PATH']}\")\n",
    "    print(f\"üìä Ground Truth: {EVAL_CONFIG['test_set_path']}\")\n",
    "    print(f\"üíæ Results: {save_eval_path}\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n‚è≥ Evaluation will execute SQL queries against the database...\")\n",
    "    print(\"üí° This may take some time depending on dataset size\\n\")\n",
    "    \n",
    "    # Show command\n",
    "    print(\"üìù Running command:\")\n",
    "    print(\" \".join(cmd))\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=os.getcwd(), check=False)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"‚úÖ Evaluation completed successfully!\")\n",
    "            print(f\"üìÅ Results saved to: {save_eval_path}\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Try to read and display metrics\n",
    "            try:\n",
    "                import json\n",
    "                with open(save_eval_path, 'r') as f:\n",
    "                    eval_results = json.load(f)\n",
    "                \n",
    "                # Calculate metrics from results\n",
    "                total = len(eval_results)\n",
    "                ex_eq = sum(1 for r in eval_results if r.get('ex_eq', 0) == 1)\n",
    "                ex_bird = sum(1 for r in eval_results if r.get('ex_bird', 0) == 1)\n",
    "                executable = sum(1 for r in eval_results if r.get('executable', 0) == 1)\n",
    "                \n",
    "                print(\"\\nüìä Evaluation Metrics:\")\n",
    "                print(f\"  Total samples: {total}\")\n",
    "                print(f\"  Executable: {executable} ({executable/total*100:.2f}%)\")\n",
    "                print(f\"  Execution Accuracy (ex_eq): {ex_eq} ({ex_eq/total*100:.2f}%)\")\n",
    "                print(f\"  Execution Accuracy (ex_bird): {ex_bird} ({ex_bird/total*100:.2f}%)\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è  Could not parse evaluation results: {e}\")\n",
    "        else:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"‚ùå Evaluation failed with return code {result.returncode}\")\n",
    "            print(\"=\"*60)\n",
    "            print(\"\\nüí° Common issues:\")\n",
    "            print(\"  - Database connection failed: Check db_conn.json\")\n",
    "            print(\"  - Database not accessible from Colab: Use VPN or different connection\")\n",
    "            print(\"  - Predictions file not found: Re-run Step 6\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: View Results (Optional)\n",
    "\n",
    "Inspect a few predictions to verify the model is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "if 'PRED_SQL_PATH' in globals() and os.path.exists(globals()['PRED_SQL_PATH']):\n",
    "    with open(globals()['PRED_SQL_PATH'], 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(f\"üìä Total predictions: {len(results)}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîç Sample Predictions (first 3)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, result in enumerate(results[:3], 1):\n",
    "        print(f\"\\n{'‚îÄ'*80}\")\n",
    "        print(f\"Sample {i}:\")\n",
    "        print(f\"{'‚îÄ'*80}\")\n",
    "        \n",
    "        # Extract question from conversations\n",
    "        if 'conversations' in result and len(result['conversations']) > 0:\n",
    "            question_text = result['conversations'][0]['content']\n",
    "            # Extract just the question part (simplified)\n",
    "            if '„ÄêQuestion„Äë' in question_text:\n",
    "                question = question_text.split('„ÄêQuestion„Äë')[1].split('\\n')[0].strip()\n",
    "            else:\n",
    "                question = question_text[:200] + \"...\" if len(question_text) > 200 else question_text\n",
    "            print(f\"\\n‚ùì Question: {question}\")\n",
    "        \n",
    "        # Show ground truth SQL\n",
    "        if 'sql' in result:\n",
    "            print(f\"\\n‚úÖ Ground Truth SQL:\")\n",
    "            print(f\"   {result['sql']}\")\n",
    "        \n",
    "        # Show predicted SQL\n",
    "        if 'pred_sql' in result:\n",
    "            print(f\"\\nü§ñ Predicted SQL:\")\n",
    "            print(f\"   {result['pred_sql']}\")\n",
    "        \n",
    "        # Show evaluation results if available\n",
    "        if 'ex_eq' in result:\n",
    "            ex_eq = result['ex_eq']\n",
    "            ex_bird = result.get('ex_bird', 0)\n",
    "            executable = result.get('executable', 0)\n",
    "            print(f\"\\nüìä Evaluation:\")\n",
    "            print(f\"   Executable: {'‚úÖ' if executable else '‚ùå'}\")\n",
    "            print(f\"   Execution Match (ex_eq): {'‚úÖ' if ex_eq else '‚ùå'}\")\n",
    "            print(f\"   Execution Match (ex_bird): {'‚úÖ' if ex_bird else '‚ùå'}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ Results inspection complete!\")\n",
    "    print(f\"\\nüí° Full results saved at: {globals()['PRED_SQL_PATH']}\")\n",
    "else:\n",
    "    print(\"‚ùå No predictions found! Please run Step 6 (Inference) first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory (OOM) Errors\n",
    "- Reduce `batch_size` to 1 in Step 5\n",
    "- Set `max_samples` to a smaller number for testing\n",
    "- Disable flash attention if enabled\n",
    "\n",
    "### Model Not Found\n",
    "- Check that `MODEL_DRIVE_PATH` in Step 4 is correct\n",
    "- Verify the model folder exists in Google Drive\n",
    "- Ensure the model folder contains all required files (config.json, tokenizer files, etc.)\n",
    "\n",
    "### Dataset Not Found\n",
    "- The test dataset should be in `evaluation/datasets/nl2sql_standard_test.json`\n",
    "- If missing, check that the repository was cloned correctly\n",
    "\n",
    "### Database Connection Issues\n",
    "- Evaluation (Step 7) requires database access\n",
    "- If you don't have database access, you can skip evaluation and manually inspect predictions\n",
    "- Make sure `db_conn.json` has the correct database credentials\n",
    "\n",
    "### Slow Inference\n",
    "- Colab free tier has limited GPU time\n",
    "- Consider using Colab Pro for longer sessions\n",
    "- Reduce `max_samples` for quick testing\n",
    "- Enable flash attention if your GPU supports it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}